{
  "metadata": {
    "kernelspec": {
      "display_name": "Pyolite",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import micropip\nawait micropip.install([\"kaibu_utils\"])",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Connect to the BioEngine",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from imjoy_rpc.hypha import connect_to_server\nserver = await connect_to_server(\n    {\"name\": \"test client\", \"server_url\": \"https://ai.imjoy.io/\", \"method_timeout\": 3000}\n)\nmodel_runner = await server.get_service(\"triton-client\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from imjoy import api\n\nimport io\nfrom PIL import Image\nimport numpy as np\nimport base64\nimport pyodide\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.ndimage as ndi\nfrom skimage import transform, util\nfrom skimage import filters, measure, segmentation\nfrom skimage.morphology import (binary_erosion, closing, disk,\n                                remove_small_holes, remove_small_objects)\n\nimport numpy as np\nfrom kaibu_utils import fetch_image, mask_to_features\n\nimport numpy as np\nfrom skimage.transform import resize\n\nnucleus_segmentation_model = \"10.5281/zenodo.6200999\"\ncell_segmentation_model = \"10.5281/zenodo.6200635\"\nclassification_model = \"10.5281/zenodo.5911832\"\n\nCOLORS =  [\"red\", \"green\", \"blue\", \"yellow\"] # microtubule, protein, nuclei, ER\nNORMALIZE = {\"mean\": [124 / 255, 117 / 255, 104 / 255], \"std\": [1 / (0.0167 * 255)] * 3}\nHIGH_THRESHOLD = 0.4\nLOW_THRESHOLD = HIGH_THRESHOLD - 0.25\n\n\nLABELS = {\n    0: 'Nucleoplasm',\n    1: 'Nuclear membrane',\n    2: 'Nucleoli',\n    3: 'Nucleoli fibrillar center',\n    4: 'Nuclear speckles',\n    5: 'Nuclear bodies',\n    6: 'Endoplasmic reticulum',\n    7: 'Golgi apparatus',\n    8: 'Intermediate filaments',\n    9: 'Actin filaments',\n    10: 'Microtubules',\n    11: 'Mitotic spindle',\n    12: 'Centrosome',\n    13: 'Plasma membrane',\n    14: 'Mitochondria',\n    15: 'Aggresome',\n    16: 'Cytosol',\n    17: 'Vesicles and punctate cytosolic patterns',\n    18: 'Negative',\n}\n\nCOLORS =  [\"red\", \"green\", \"blue\", \"yellow\"]\n\n\nasync def fetch_hpa_image(image_id):\n    crops = []\n    for color in COLORS:\n        image = await fetch_image(f'https://images.proteinatlas.org/{image_id}_{color}.jpg', grayscale=True)\n        crops.append(image)\n    image = np.stack(crops, axis=0)\n    # assert image.shape == (4, 128, 128)\n    return image\n\ndef __fill_holes(image):\n    \"\"\"Fill_holes for labelled image, with a unique number.\"\"\"\n    boundaries = segmentation.find_boundaries(image)\n    image = np.multiply(image, np.invert(boundaries))\n    image = ndi.binary_fill_holes(image > 0)\n    image = ndi.label(image)[0]\n    return image\n\n\ndef label_nuclei(nuclei_pred):\n    \"\"\"Return the labeled nuclei mask data array.\n    This function works best for Human Protein Atlas cell images with\n    predictions from the CellSegmentator class.\n    Keyword arguments:\n    nuclei_pred -- a 3D numpy array of a prediction from a nuclei image.\n    Returns:\n    nuclei-label -- An array with unique numbers for each found nuclei\n                    in the nuclei_pred. A value of 0 in the array is\n                    considered background, and the values 1-n is the\n                    areas of the cells 1-n.\n    \"\"\"\n    img_copy = np.copy(nuclei_pred[..., 2])\n    borders = (nuclei_pred[..., 1] > 0.05).astype(np.uint8)\n    m = img_copy * (1 - borders)\n\n    img_copy[m <= LOW_THRESHOLD] = 0\n    img_copy[m > LOW_THRESHOLD] = 1\n    img_copy = img_copy.astype(np.bool_)\n    img_copy = binary_erosion(img_copy)\n    # TODO: Add parameter for remove small object size for\n    #       differently scaled images.\n    # img_copy = remove_small_objects(img_copy, 500)\n    img_copy = img_copy.astype(np.uint8)\n    markers = measure.label(img_copy).astype(np.uint32)\n\n    mask_img = np.copy(nuclei_pred[..., 2])\n    mask_img[mask_img <= HIGH_THRESHOLD] = 0\n    mask_img[mask_img > HIGH_THRESHOLD] = 1\n    mask_img = mask_img.astype(np.bool_)\n    mask_img = remove_small_holes(mask_img, 1000)\n    # TODO: Figure out good value for remove small objects.\n    # mask_img = remove_small_objects(mask_img, 8)\n    mask_img = mask_img.astype(np.uint8)\n    nuclei_label = segmentation.watershed(\n        mask_img, markers, mask=mask_img, watershed_line=True\n    )\n    nuclei_label = remove_small_objects(nuclei_label, 2500)\n    nuclei_label = measure.label(nuclei_label)\n    return nuclei_label\n\n\ndef label_cell(nuclei_pred, cell_pred):\n    \"\"\"Label the cells and the nuclei.\n    Keyword arguments:\n    nuclei_pred -- a 3D numpy array of a prediction from a nuclei image.\n    cell_pred -- a 3D numpy array of a prediction from a cell image.\n    Returns:\n    A tuple containing:\n    nuclei-label -- A nuclei mask data array.\n    cell-label  -- A cell mask data array.\n    0's in the data arrays indicate background while a continous\n    strech of a specific number indicates the area for a specific\n    cell.\n    The same value in cell mask and nuclei mask refers to the identical cell.\n    NOTE: The nuclei labeling from this function will be sligthly\n    different from the values in :func:`label_nuclei` as this version\n    will use information from the cell-predictions to make better\n    estimates.\n    \"\"\"\n    def __wsh(\n        mask_img,\n        threshold,\n        border_img,\n        seeds,\n        threshold_adjustment=0.35,\n        small_object_size_cutoff=10,\n    ):\n        img_copy = np.copy(mask_img)\n        m = seeds * border_img  # * dt\n        img_copy[m <= threshold + threshold_adjustment] = 0\n        img_copy[m > threshold + threshold_adjustment] = 1\n        img_copy = img_copy.astype(np.bool_)\n        img_copy = remove_small_objects(img_copy, small_object_size_cutoff).astype(\n            np.uint8\n        )\n\n        mask_img[mask_img <= threshold] = 0\n        mask_img[mask_img > threshold] = 1\n        mask_img = mask_img.astype(np.bool_)\n        mask_img = remove_small_holes(mask_img, 1000)\n        mask_img = remove_small_objects(mask_img, 8).astype(np.uint8)\n        markers = ndi.label(img_copy, output=np.uint32)[0]\n        labeled_array = segmentation.watershed(\n            mask_img, markers, mask=mask_img, watershed_line=True\n        )\n        return labeled_array\n\n    nuclei_label = __wsh(\n        nuclei_pred[..., 2] / 255.0,\n        0.4,\n        1 - (nuclei_pred[..., 1] + cell_pred[..., 1]) / 255.0 > 0.05,\n        nuclei_pred[..., 2] / 255,\n        threshold_adjustment=-0.25,\n        small_object_size_cutoff=500,\n    )\n\n    # for hpa_image, to remove the small pseduo nuclei\n    nuclei_label = remove_small_objects(nuclei_label, 2500)\n    nuclei_label = measure.label(nuclei_label)\n    # this is to remove the cell borders' signal from cell mask.\n    # could use np.logical_and with some revision, to replace this func.\n    # Tuned for segmentation hpa images\n    threshold_value = max(0.22, filters.threshold_otsu(cell_pred[..., 2] / 255) * 0.5)\n    # exclude the green area first\n    cell_region = np.multiply(\n        cell_pred[..., 2] / 255 > threshold_value,\n        np.invert(np.asarray(cell_pred[..., 1] / 255 > 0.05, dtype=np.int8)),\n    )\n    sk = np.asarray(cell_region, dtype=np.int8)\n    distance = np.clip(cell_pred[..., 2], 255 * threshold_value, cell_pred[..., 2])\n    cell_label = segmentation.watershed(-distance, nuclei_label, mask=sk)\n    cell_label = remove_small_objects(cell_label, 5500).astype(np.uint8)\n    selem = disk(6)\n    cell_label = closing(cell_label, selem)\n    cell_label = __fill_holes(cell_label)\n    # this part is to use green channel, and extend cell label to green channel\n    # benefit is to exclude cells clear on border but without nucleus\n    sk = np.asarray(\n        np.add(\n            np.asarray(cell_label > 0, dtype=np.int8),\n            np.asarray(cell_pred[..., 1] / 255 > 0.05, dtype=np.int8),\n        )\n        > 0,\n        dtype=np.int8,\n    )\n    cell_label = segmentation.watershed(-distance, cell_label, mask=sk)\n    cell_label = __fill_holes(cell_label)\n    cell_label = np.asarray(cell_label > 0, dtype=np.uint8)\n    cell_label = measure.label(cell_label)\n    cell_label = remove_small_objects(cell_label, 5500)\n    cell_label = measure.label(cell_label)\n    cell_label = np.asarray(cell_label, dtype=np.uint16)\n    nuclei_label = np.multiply(cell_label > 0, nuclei_label) > 0\n    nuclei_label = measure.label(nuclei_label)\n    nuclei_label = remove_small_objects(nuclei_label, 2500)\n    nuclei_label = np.multiply(cell_label, nuclei_label > 0)\n\n    return nuclei_label, cell_label\n\n\n\ndef preprocess(image, scale_factor=0.25):\n    assert len(image.shape) == 3\n    image = transform.rescale(image, scale_factor, channel_axis=2)\n    # nuc_image = np.dstack((image[..., 2], image[..., 2], image[..., 2]))\n    image = image.transpose([2, 0, 1])\n    return image\n\ndef run_model_torch(model, imgs, scale_factor=0.25):\n    import torch\n    imgs = torch.tensor(imgs).float()\n    mean = torch.as_tensor(NORMALIZE[\"mean\"])\n    std = torch.as_tensor(NORMALIZE[\"std\"])\n    imgs = imgs.sub_(mean[:, None, None]).div_(std[:, None, None])\n    # np.save(\"test_input.npy\", imgs)\n    imgs = model(imgs)\n    imgs = imgs.to(\"cpu\").detach().numpy()\n    # np.save(\"test_output.npy\", imgs)\n    imgs = transform.rescale(imgs[0].transpose([1, 2, 0]), 1.0/scale_factor, channel_axis=2)\n    imgs = util.img_as_ubyte(imgs)\n    return imgs\n\nasync def segment(model, imgs, scale_factor=0.25):\n    imgs = preprocess(imgs, scale_factor=0.25)\n    image = imgs[None, :, :, :].astype('float32')\n    kwargs = {\"inputs\": [image], \"model_id\": model}\n    ret = await model_runner.execute(\n        inputs=[kwargs],\n        model_name=\"bioengine-model-runner\",\n        serialization=\"imjoy\",\n    )\n    result = ret[\"result\"]\n    # result = await model_runner.execute_model([image], model)\n    if result['success']:\n        imgs = result['outputs'][0]\n        # np.save(\"test_output.npy\", imgs)\n        imgs = transform.rescale(imgs[0].transpose([1, 2, 0]), 1.0/scale_factor, channel_axis=2)\n        imgs = util.img_as_ubyte(imgs)\n        return imgs\n    else:\n        raise Exception(f\"Failed to run model: {model}, error: {result['error']}\")\n\nasync def classify(model, image, threshold=0.3, expected_shape=[4, 128, 128]):\n    image = image.transpose(2, 0, 1)  # HxWxC to CxHxW\n    image = resize(image, expected_shape)\n    # plt.imshow(image[0:3, :, :].transpose(1,2,0))\n    # after resizing, the pixel range will become 0~1\n    image *= 255\n    image = image[None, :, :, :].astype('float32')\n    kwargs = {\"inputs\": [image], \"model_id\": model}\n    ret = await model_runner.execute(\n        inputs=[kwargs],\n        model_name=\"bioengine-model-runner\",\n        serialization=\"imjoy\",\n    )\n    result = ret[\"result\"]\n    # assert result[\"success\"] == True, result[\"error\"]\n    # assert result[\"outputs\"][0].shape == (1, 3, 128, 128), str(\n    #     result[\"outputs\"][0].shape\n    # )\n    # result = await model_runner.execute_model([image], model)\n    if result['success']:\n        features, classes = result['outputs']\n        preds = [(LABELS[i], prob) for i, prob in enumerate(classes[0].tolist()) if prob>threshold]\n        return preds\n    else:\n        raise Exception(f\"Failed to run model: {model}, error: {result['error']}\")\n\n\ndef cell_crop_augment(image, mask, paddings=(20, 20, 20, 20)):\n    top, bottom, left, right = paddings\n    label_image = measure.label(mask)\n    max_area = 0\n    for region in measure.regionprops(label_image):\n        if region.area > max_area:\n            max_area = region.area\n            min_row, min_col, max_row, max_col = region.bbox\n\n    min_row, min_col = max(min_row - top, 0), max(min_col - left, 0)\n    max_row, max_col = min(max_row + bottom, mask.shape[0]), min(max_col + right, mask.shape[1])\n\n    image = image[min_row:max_row, min_col:max_col]\n    mask = mask[min_row:max_row, min_col:max_col]\n    return image, mask\n\ndef generate_cell_indices(cell_mask):\n    cell_indices = np.sort(list(set(np.unique(cell_mask).tolist()) - {0, }))\n    return cell_indices.tolist()\n\ndef crop_image(image_raw, mask_raw):\n    cell_indices = generate_cell_indices(mask_raw)\n    crop_images = []\n    for maskid in cell_indices:\n        image = image_raw.copy()\n        mask = mask_raw.copy()\n        image[mask != maskid] = 0\n        image, _ = cell_crop_augment(image, (mask == maskid).astype('uint8'))\n        crop_images.append(image)\n    return zip(cell_indices, crop_images)\n\ndef read_image(bytes, name=None, grayscale=False, size=None):\n    buffer = io.BytesIO(bytes)\n    buffer.name = name or url.split('?')[0].split('/')[1]\n    image = Image.open(buffer).convert('L')\n    if grayscale:\n        image = image.convert('L')\n    if size:\n        image = image.resize(size=size)\n    image = np.array(image)\n    return image\n\n\ndef encode_image(image):\n    image = Image.fromarray(image)\n    buffered = BytesIO()\n    image.save(buffered, format=\"PNG\")\n    img_str = 'data:image/png;base64,' + base64.b64encode(buffered.getvalue()).decode('ascii')\n    return img_str\n\n\ndef watershed(image, seed=None):\n    assert seed is not None\n    nuclei_mask = label_nuclei(seed)\n    nuclei_mask, cell_mask = label_cell(seed, image)\n    return cell_mask",
      "metadata": {
        "trusted": true
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Load image",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "image_id = \"115/672_E2_1\"\nimage_raw = await fetch_hpa_image(image_id)\nnuc_image = image_raw[2, :, :]\nnuc_image = np.stack((nuc_image, nuc_image, nuc_image), axis=-1)\ncell_image = np.stack((image_raw[0, :, :], image_raw[3, :, :], image_raw[2, :, :]), axis=-1)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Segment Nuclei",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "nucleus_segmentation_model = \"conscientious-seashell\"\nnuclei_prediction = await segment(nucleus_segmentation_model, nuc_image)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Segment Cells",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "cell_segmentation_model = \"loyal-parrot\"\ncell_prediction = await segment(cell_segmentation_model, cell_image)\ncell_mask = watershed(cell_prediction, seed=nuclei_prediction)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Classify Protein Pattern in each Cell",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "classification_model = \"straightforward-crocodile\"\nprotein_predictions = {}\ncell_images = crop_image(image_raw.transpose(1,2,0), cell_mask)\nfor mask_id, image_crop in cell_images:\n    preds = await classify(classification_model, image_crop)\n    protein_predictions[mask_id] = preds\n    print(f\"Prediction for cell {mask_id}: {preds}\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Visualize Results in Kaibu",
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": "class ImJoyPlugin():\n    async def setup(self):\n        viewer = await api.createWindow(\n            src=\"https://kaibu.org\"\n        )\n        viewer.view_image(f\"https://images.proteinatlas.org/{image_id}_blue_red_green.jpg\")\n        shapes = mask_to_features(np.flipud(cell_mask))\n        names = []\n        for i in range(len(shapes)):\n            pred = protein_predictions[i+1]\n            label = [f'{p[0]}({p[1]:.2})' for p in pred]\n            names.append(\",\".join(label))\n        await viewer.add_shapes(shapes, label=names, name=\"Prediction\", edge_color='#4FED10', text_placement='point')\n\napi.export(ImJoyPlugin())",
      "metadata": {
        "trusted": true
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "window.connectPlugin && window.connectPlugin(\"d6654e31-b45b-4b77-b328-f942d799bfd9\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<div id=\"865fc11f-e461-4b84-ae73-17cad09521ec\"></div>"
          },
          "metadata": {}
        },
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<Future finished result=[]>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Constantin's napari code",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import bioimageio.core\nimport napari\n\ndef segment_cells(image):\n    nucleus_model = bioimageio.core.load_resource_description(\n        \"conscientious-seashell\"\n    )\n    with bioimageio.create_prediction_pipeline(nucleus_model) as pp:\n        nucleus_predictions = pp(image)\n    nuclei = label(nucleus_predictions > 0.5)\n\n    membrane_model = bioimageio.core.load_resource_description(\n        \"loyal-parrot\"\n    )\n    with bioimageio.create_prediction_pipeline(membranes_model) as pp:\n        membranes = pp(image)\n\n    cells = watershed(membranes, seeds=nuclei)\n    return cells\n\ndef classify_cells(image, cells):\n    classification_model = bioimageio.core.load_resource_description(\n        \"straightforward-crocodile\"\n    )\n\n    classes = []\n    with bioimageio.create_prediction_pipeline(classification_model) as pp:\n        for cell in cells:\n            this_class = pp(image[cell.bounding_box])\n            classes.append(this_class)\n    return classes\n\ndef main(image):\n    cells = segment_cells(image)\n    classes = classify_cells(image, cells)\n    visualize_in_napari(image, cells, classes)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
